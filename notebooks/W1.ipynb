{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1 - Introduction\n",
    "\n",
    "By Group XX:\n",
    "\n",
    "-   Aleksandar Lukic - s194066\n",
    "-   Paula Barho - s242926\n",
    "-   Victor Gustav Harbo Rasmussen - s204475"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Predictive policing. A case to learn from\n",
    "\n",
    "Start by reading the article from [sciencemag.org](https://www.sciencemag.org/news/2016/09/can-predictive-policing-prevent-crime-it-happens).\n",
    "\n",
    "We will be using data from [dataSF](https://datasf.org/opendata/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- According to the article, is predictive policing better than best practice techniques for law enforcement? The article is from 2016. Take a look around the web, does this still seem to be the case in 2024? (hint, when you evaluate the evidence consider the source)\n",
    "\n",
    "- List and explain some of the possible issues with predictive policing according to the article.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Load some crime-data into your Jupyter notebook\n",
    "\n",
    "Using pandas, we will be loading data from local files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preamble for Pandas display options\n",
    "\n",
    "These options enables the Pandas output to be fully displayed and expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pandas display options to show all columns for .head command\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', None)        # Auto-detect the display width\n",
    "pd.set_option('display.max_colwidth', None) # Show full content of each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data from .csv\n",
    "\n",
    "Get the datasets from the data folder in the repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get path of data directory\n",
    "data_path = os.path.abspath(os.path.join(os.pardir, \"data\"))\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from csv files\n",
    "csv_1_name = \"Police_Department_Incident_Reports__Historical_2003_to_May_2018_20250210.csv\"\n",
    "csv_2_name = \"Police_Department_Incident_Reports__2018_to_Present_20250210.csv\"\n",
    "csv_1_path = os.path.join(data_path, csv_1_name)\n",
    "csv_2_path = os.path.join(data_path, csv_2_name)\n",
    "df_1 = pd.read_csv(csv_1_path)\n",
    "df_2 = pd.read_csv(csv_2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display shape of dataframes\n",
    "print(\"df_1:\", df_1.shape)\n",
    "print(\"df_2:\", df_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the datasets\n",
    "\n",
    "In order to be able to concatinate the two datasets, we must ensure that they are of same diminsonality and naming- and type-conventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shrinking the data\n",
    "\n",
    "The datasets are very large and contain some informations which we are currently not interested in keeping. Thus, we can extract the columns that are useful and discard the remaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to keep for df_1\n",
    "columns_to_keep_1 = [\n",
    "    'Date',\n",
    "    'Time',\n",
    "    'Category',\n",
    "    'DayOfWeek',\n",
    "    'X',\n",
    "    'Y',\n",
    "    'PdDistrict'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to keep for df_2\n",
    "columns_to_keep_2 = [\n",
    "    'Incident Date',\n",
    "    'Incident Time',\n",
    "    'Incident Category',\n",
    "    'Incident Day of Week',\n",
    "    'Latitude',\n",
    "    'Longitude',\n",
    "    'Police District'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the columns specified for keeping\n",
    "df_1 = df_1[columns_to_keep_1]\n",
    "df_2 = df_2[columns_to_keep_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename the columns\n",
    "\n",
    "Firstly, we can start by renaming the columns so that the can be joined later on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.rename(columns={\n",
    "    'Date': 'Date',\n",
    "    'Time': 'Time',\n",
    "    'Category': 'Category',\n",
    "    'DayOfWeek': 'Day of Week',\n",
    "    \"X\": \"Longitude (X)\",\n",
    "    \"Y\": \"Latitude (Y)\",\n",
    "    'PdDistrict': 'Police District'\n",
    "    }\n",
    ")\n",
    "\n",
    "df_2 = df_2.rename(columns={\n",
    "    'Incident Date': 'Date',\n",
    "    'Incident Time': 'Time',\n",
    "    'Incident Category': 'Category',\n",
    "    'Incident Day of Week': 'Day of Week',\n",
    "    'Longitude': 'Longitude (X)',\n",
    "    'Latitude': 'Latitude (Y)',\n",
    "    'Police District': 'Police District'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align date and time formats\n",
    "\n",
    "The two datasets abide by different time conventions. Thus, it is neccessary to align them with a single convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the date and time\n",
    "df_1_time = pd.DataFrame(df_1)\n",
    "\n",
    "# Convert \"Date\" column to datetime format\n",
    "df_1_time[\"Date\"] = pd.to_datetime(df_1_time[\"Date\"], format=\"%m/%d/%Y\")\n",
    "\n",
    "# Create new columns from \"Date\"\n",
    "df_1_time[\"Day\"] = df_1_time[\"Date\"].dt.day\n",
    "df_1_time[\"Month\"] = df_1_time[\"Date\"].dt.strftime(\"%B\")  # Month name\n",
    "df_1_time[\"Year\"] = df_1_time[\"Date\"].dt.year\n",
    "\n",
    "# Extract the hour from the \"Time\" column to create \"TimeOfDay\"\n",
    "df_1_time[\"Hour\"] = pd.to_datetime(df_1_time[\"Time\"], format=\"%H:%M\").dt.hour\n",
    "\n",
    "# Drop the original \"Date\" and \"Time\" columns\n",
    "df_1_time = df_1_time.drop(columns=[\"Date\", \"Time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the date and time\n",
    "df_2_time = pd.DataFrame(df_2)\n",
    "\n",
    "# Convert \"Date\" column to datetime format\n",
    "df_2_time[\"Date\"] = pd.to_datetime(df_2_time[\"Date\"], format=\"%Y/%m/%d\")\n",
    "\n",
    "# Create new columns from \"Date\"\n",
    "df_2_time[\"Day\"] = df_2_time[\"Date\"].dt.day\n",
    "df_2_time[\"Month\"] = df_2_time[\"Date\"].dt.strftime(\"%B\")  # Month name\n",
    "df_2_time[\"Year\"] = df_2_time[\"Date\"].dt.year\n",
    "\n",
    "# Extract the hour from the \"Time\" column to create \"TimeOfDay\"\n",
    "df_2_time[\"Hour\"] = pd.to_datetime(df_2_time[\"Time\"], format=\"%H:%M\").dt.hour\n",
    "\n",
    "# Drop the original \"Date\" and \"Time\" columns\n",
    "df_2_time = df_2_time.drop(columns=[\"Date\", \"Time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_time.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_time.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override the original dataframes with the new ones\n",
    "df_1 = df_1_time\n",
    "df_2 = df_2_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align Category and Police Department columns\n",
    "\n",
    "The two datasets both store some lookup values for the Category and Police Department columns respectivily. However, the values are not formated the same and thus will not be seen as equal to each other. Therefore, we need to align these manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_1['Category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_2['Category'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the second dataset is capitalized, we can convert it to uppercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['Category'] = df_2['Category'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_2['Category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = set(np.concatenate((\n",
    "    df_1['Category'].unique(), \n",
    "    df_2['Category'].unique()\n",
    "    ), axis=0\n",
    "))\n",
    "\n",
    "print(\"No. of incedent categories:\", len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the naming between the two datasets is a bit off, we adjust the names in the second dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {\n",
    "    'DRUG VIOLATION': 'DRUG/NARCOTIC',\n",
    "    'DRUG OFFENSE': 'DRUG/NARCOTIC',\n",
    "    'LARCENY THEFT': 'LARCENY/THEFT',\n",
    "    'MALICIOUS MISCHIEF': 'VANDALISM',  \n",
    "    'MOTOR VEHICLE THEFT': 'VEHICLE THEFT',\n",
    "    'MOTOR VEHICLE THEFT?': 'VEHICLE THEFT',\n",
    "    'WEAPONS CARRYING ETC': 'WEAPON LAWS',\n",
    "    'WEAPONS OFFENCE': 'WEAPON LAWS',\n",
    "    'WEAPONS OFFENSE': 'WEAPON LAWS',\n",
    "    \n",
    "    # Additional mappings for edge cases\n",
    "    'TRAFFIC VIOLATION ARREST': 'DRIVING UNDER THE INFLUENCE',  # If DUI is included here \n",
    "    'SUSPICIOUS OCC': 'TRESPASS',\n",
    "    'SUSPICIOUS': 'TRESPASS',\n",
    "    'LIQUOR LAWS': 'DRUNKENNESS'  # If liquor law violations include public drunkenness \n",
    "}\n",
    "\n",
    "# Replace the categories in the dataframes with the new mappings\n",
    "df_2['Category'] = df_2['Category'].replace(category_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to keep only the rows containing the focus crimes as defined below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_crimes = [\n",
    "    'ASSAULT',\n",
    "    'BURGLARY',\n",
    "    'DISORDERLY CONDUCT',\n",
    "    'DRIVING UNDER THE INFLUENCE',\n",
    "    'DRUG/NARCOTIC',\n",
    "    'DRUNKENNESS',\n",
    "    'LARCENY/THEFT',\n",
    "    'PROSTITUTION',\n",
    "    'ROBBERY',\n",
    "    'STOLEN PROPERTY',\n",
    "    'TRESPASS',\n",
    "    'VANDALISM',\n",
    "    'VEHICLE THEFT',\n",
    "    'WEAPON LAWS'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the rows where the \"Category\" is in the focus_crimes list\n",
    "df_1_filtered = df_1[df_1['Category'].isin(focus_crimes)]\n",
    "df_2_filtered = df_2[df_2['Category'].isin(focus_crimes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"df_1:\", df_1.shape)\n",
    "print(\"df_2:\", df_2.shape)\n",
    "print(\"df_1_filtered:\", df_1_filtered.shape)\n",
    "print(\"df_2_filtered:\", df_2_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1_filtered\n",
    "df_2 = df_2_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now do the same for the police department column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_1['Police District'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_2['Police District'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['Police District'] = df_2['Police District'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "police_districts = set(np.concatenate((\n",
    "    df_1['Police District'].unique(), \n",
    "    df_2['Police District'].unique()\n",
    "    ), axis=0\n",
    "))\n",
    "\n",
    "print(\"No. of Police Districts:\", len(police_districts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "police_districts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the two datasets into one\n",
    "\n",
    "Finally, we can now merge the two datasets by aligning their columns and then concatenating them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that both DataFrames have the same columns in the same order\n",
    "columns = [\n",
    "    'Category', \n",
    "    'Police District', \n",
    "    'Longitude (X)', \n",
    "    'Latitude (Y)',  \n",
    "    'Day of Week',\n",
    "    'Hour', \n",
    "    'Day', \n",
    "    'Month', \n",
    "    'Year'\n",
    "]\n",
    "\n",
    "df_1 = df_1[columns]\n",
    "df_2 = df_2[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.concat([df_1, df_2], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data by Year, Month, Day, and Hour in ascending order\n",
    "df_sorted = df_merged.sort_values(\n",
    "    by=['Year', 'Month', 'Day', 'Hour'], \n",
    "    ascending=[True, True, True, True], \n",
    "    na_position='last'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index of the sorted DataFrame\n",
    "df_reindexed = df_sorted.reset_index()\n",
    "df_reindexed.drop(columns=['index'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"df_reindexed:\", df_reindexed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reindexed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reindexed.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned and merged data to a new csv file\n",
    "cleaned_data_path = os.path.join(data_path, \"Police_Department_Incident_Reports_Complete.csv\")\n",
    "df_reindexed.to_csv(cleaned_data_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple statistics\n",
    "\n",
    "Now generate the following simple statistics\n",
    "- Report the total number of crimes in the dataset.\n",
    "- List the various categories of crime. How many are there?\n",
    "- List the number of crimes in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing total number of crimes\n",
    "total_crimes = df_reindexed.shape[0]\n",
    "print(f\"Total number of crimes: {total_crimes}\")\n",
    "\n",
    "# List the number of crimes in each category\n",
    "category_counts = df_reindexed['Category'].value_counts()\n",
    "print(\"Number of crimes in each category:\")\n",
    "print(category_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: The types of crimes.\n",
    "\n",
    "- We have already counted the number of crimes in each category. What is the most commonly occurring category of crime? What is the least frequently occurring?\n",
    "\n",
    "The most commonly occurring category of crime is larceny/theft and the lest frequently occurring one is drunkenness. \n",
    "\n",
    "- Did you run into categories changing across your two data periods? If yes, think about how to deal with those issues. There's no right answer but reflect on your decisions. (And don't spend too much energy on this, since we'll only be working on a subset of the crimes long-term, see Focus Crimes below.)\n",
    "\n",
    "Few categories overlap, naming is different, the number of crimes reported increases drastically. We only kept the same categories across both data sets. \n",
    "\n",
    "- Create a bar-plot over crime occurrences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "category_counts.plot(kind='bar')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Crime Occurrences by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Number of Crimes')\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Temporal patterns.\n",
    "\n",
    "- What is the year with most crimes?\n",
    "- What is the year with the fewest crimes?.\n",
    "- Create a barplot of crimes-per-year (years on the -axis, crime-counts on the -axis).\n",
    "- Finally, Police chief Suneman is interested in the temporal development of only a **subset of categories, the so-called *focus crimes***. Those categories are listed below (for convenient copy-paste action). Create bar-charts displaying the year-by-year development of each of these categories across the years 2003-2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by year and count the number of crimes\n",
    "yearly_crime_counts = df_reindexed['Year'].value_counts()\n",
    "\n",
    "# Find the year with the most crimes\n",
    "year_most_crimes = yearly_crime_counts.idxmax()\n",
    "most_crimes = yearly_crime_counts.max()\n",
    "\n",
    "# Find the year with the fewest crimes\n",
    "year_fewest_crimes = yearly_crime_counts.idxmin()\n",
    "fewest_crimes = yearly_crime_counts.min()\n",
    "\n",
    "print(f\"The year with the most crimes is {year_most_crimes} with {most_crimes} crimes.\")\n",
    "print(f\"The year with the fewest crimes is {year_fewest_crimes} with {fewest_crimes} crimes.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
